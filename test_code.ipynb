{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Policy generator. Generates the trading policy based on the forecast. Currently buys low, sells high\n",
    "\n",
    "class policy_generator():\n",
    "    \n",
    "    # Initialise variables. \n",
    "    def __init__(self,wallet):\n",
    "        self.policy = None\n",
    "        self.stocks_owned = 0\n",
    "        self.wallet = wallet\n",
    "        self.policy_record = []\n",
    "        self.forecast_record = []\n",
    "        \n",
    "    # Positive number check\n",
    "    def is_positive(self,x):\n",
    "        if x>=0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    # Find change of each value wrt the next\n",
    "    def diff_seq(self,data):\n",
    "        diff = []\n",
    "        for i in range(len(data)-1):\n",
    "            diff = np.append(diff,data[i+1]-data[i])\n",
    "        return diff\n",
    "    \n",
    "    \n",
    "    # Generate the forecast\n",
    "    def generate(self,forecast):\n",
    "        \n",
    "        diff = self.diff_seq(forecast)\n",
    "        policy = []\n",
    "        \n",
    "        # For the first value, if low buy otherwise wait\n",
    "        if self.is_positive(diff[0]):\n",
    "            policy = ['buy']\n",
    "        else:\n",
    "            policy = ['wait']\n",
    "\n",
    "        # Slide window of size 3 over the diff array looking for high and low points\n",
    "        for i in range(2,len(diff)+1):\n",
    "            window = np.asarray(forecast[i-2:i+1])\n",
    "        \n",
    "            # high point - sell high\n",
    "            if window[1]> window[0] and window[1]>window[2]:\n",
    "                 policy = np.append(policy,'sell')\n",
    "            # low point - buy low\n",
    "            elif window[1]< window[0] and window[1]<window[2]:\n",
    "                 policy = np.append(policy,'buy')\n",
    "            # Otherwise wait for optimal point\n",
    "            else: \n",
    "                 policy = np.append(policy,'wait')\n",
    "\n",
    "        # Finally sell at the end of the sequence\n",
    "        policy = np.append(policy,'sell')\n",
    "        self.policy = policy\n",
    "        return policy\n",
    "        \n",
    "    \n",
    "    # Buy stocks -- buy as many as possible\n",
    "    def buy_stocks(self,price):\n",
    "        self.stocks_owned = int(self.wallet/price)\n",
    "        self.wallet = self.wallet - (self.stocks_owned*price)\n",
    "        \n",
    "    \n",
    "    # Sell stocks -- sell all stocks at market rate\n",
    "    def sell_stocks(self,price):\n",
    "        self.wallet = self.wallet + (self.stocks_owned*price)\n",
    "        self.stocks_owned = 0\n",
    "        \n",
    "    \n",
    "    # Iterate over the policy and alter wallet accordingly based on market rate\n",
    "    def execute_policy(self,policy,true_data):\n",
    "\n",
    "        for i in range(len(policy)):\n",
    "            \n",
    "            self.policy_record = np.append(self.policy_record,policy[i])\n",
    "            \n",
    "            if policy[i] == 'buy':\n",
    "                self.buy_stocks(true_data[i])\n",
    "            elif policy[i] =='wait':\n",
    "                continue\n",
    "            elif policy[i] == 'sell':\n",
    "                self.sell_stocks(true_data[i])\n",
    "                \n",
    "                \n",
    "\n",
    "                \n",
    "    def update(self,forecast,i=False):\n",
    "        self.forecast_record = np.append(self.forecast_record,forecast)\n",
    "        policy = self.generate(self.forecast_record)\n",
    "    \n",
    "        \n",
    "        # If it is not the end delete relevant indexes.\n",
    "#         if end:\n",
    "#             pass\n",
    "#         else:\n",
    "        index = np.arange(int(len(forecast)/2))+len(self.forecast_record)-int(len(forecast)/2)\n",
    "        self.forecast_record = np.delete(self.forecast_record,index)\n",
    "        policy = np.delete(policy,index)\n",
    "            \n",
    "        \n",
    "            \n",
    "        # If first iteration. Policy is the first half of the array\n",
    "        if i:\n",
    "            new_policy = policy\n",
    "            \n",
    "        # If not end and not first take first half of policy\n",
    "        else:\n",
    "            new_policy = policy[len(policy)-int(len(forecast)/2):]\n",
    "#         # If end then take the whole end of sequence\n",
    "#         else:\n",
    "#             new_policy = policy[len(policy)-len(forecast):]\n",
    "        \n",
    "\n",
    "        return new_policy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "a = [1,1,2,3,4,5,6,7]\n",
    "b = [12,3,51,4,3,1,2,4]\n",
    "for i in range(10):\n",
    "    a = np.concatenate((b,a))\n",
    "a = np.reshape(a,(11,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ellio\\documents\\miniconda3\\lib\\site-packages\\ipykernel_launcher.py:68: RuntimeWarning: overflow encountered in long_scalars\n"
     ]
    }
   ],
   "source": [
    "p = policy_generator(1000)\n",
    "\n",
    "forecast_horizon = 8    \n",
    "start = True\n",
    "\n",
    "for f in range(len(a)):\n",
    "    forecast = a[f]\n",
    "    \n",
    "    updated_policy = p.update(forecast,start)\n",
    "    p.execute_policy(updated_policy,data)\n",
    "    start = False\n",
    "        \n",
    "        \n",
    "policy = p.policy_record\n",
    "# print(np.where(policy!=p.generate(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wait' 'buy' 'sell' 'wait' 'wait' 'buy' 'wait' 'wait' 'sell' 'buy' 'sell'\n",
      " 'wait' 'wait' 'buy' 'wait' 'wait' 'sell' 'buy' 'sell' 'wait' 'wait' 'buy'\n",
      " 'wait' 'wait' 'sell' 'buy' 'sell' 'wait' 'wait' 'buy' 'wait' 'wait'\n",
      " 'sell' 'buy' 'sell' 'wait' 'wait' 'buy' 'wait' 'wait' 'sell' 'buy' 'sell'\n",
      " 'wait' 'wait' 'buy' 'wait' 'wait' 'sell' 'buy' 'sell' 'wait' 'wait' 'buy'\n",
      " 'wait' 'wait' 'sell' 'buy' 'sell' 'wait' 'wait' 'buy' 'wait' 'wait'\n",
      " 'sell' 'buy' 'sell' 'wait' 'wait' 'buy' 'wait' 'wait' 'sell' 'buy' 'sell'\n",
      " 'wait' 'wait' 'buy' 'wait' 'sell' 'wait' 'wait' 'wait' 'wait' 'wait'\n",
      " 'wait']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: objects cannot be broadcast to a single shape",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-8b862f60645a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m86\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrue\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: shape mismatch: objects cannot be broadcast to a single shape"
     ]
    }
   ],
   "source": [
    "true = p.generate(a.ravel())[:86]\n",
    "print(true)\n",
    "\n",
    "\n",
    "print(policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seq2Seq NN model\n",
    "\n",
    "class model():\n",
    "    \n",
    "    def __init__(self,config):\n",
    "        self.config = config\n",
    "        self.wallet_change = []\n",
    "        self.wallet = None\n",
    "        \n",
    "        \n",
    "\n",
    "    def build_graph(self,feed_previous = False):\n",
    "        \n",
    "        from tensorflow.contrib import rnn\n",
    "        from tensorflow.python.ops import variable_scope\n",
    "        from tensorflow.python.framework import dtypes\n",
    "        \n",
    "        \n",
    "        print(\"Building graph\")\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "\n",
    "        global_step = tf.Variable(\n",
    "                      initial_value=0,\n",
    "                      name=\"global_step\",\n",
    "                      trainable=False,\n",
    "                      collections=[tf.GraphKeys.GLOBAL_STEP, tf.GraphKeys.GLOBAL_VARIABLES])\n",
    "\n",
    "        weights = {\n",
    "            'out': tf.get_variable('Weights_out', \\\n",
    "                                   shape = [self.config.hidden_dim, self.config.output_dim], \\\n",
    "                                   dtype = tf.float32, \\\n",
    "                                   initializer = tf.truncated_normal_initializer()),\n",
    "        }\n",
    "        print(\"    - Weights init\")\n",
    "\n",
    "        biases = {\n",
    "            'out': tf.get_variable('Biases_out', \\\n",
    "                                   shape = [self.config.output_dim], \\\n",
    "                                   dtype = tf.float32, \\\n",
    "                                   initializer = tf.constant_initializer(0.)),\n",
    "        }\n",
    "        print(\"    - Biases init\")\n",
    "        with tf.variable_scope('Seq2seq'):\n",
    "            # Encoder: inputs\n",
    "            enc_inp = [\n",
    "                tf.placeholder(tf.float32, shape=(None, self.config.input_dim), name=\"inp_{}\".format(t))\n",
    "                   for t in range(self.config.input_seq_len)\n",
    "            ]\n",
    "\n",
    "            # Decoder: target outputs\n",
    "            target_seq = [\n",
    "                tf.placeholder(tf.float32, shape=(None, self.config.output_dim), name=\"y\".format(t))\n",
    "                  for t in range(self.config.output_seq_len)\n",
    "            ]\n",
    "\n",
    "            # Give a \"GO\" token to the decoder.\n",
    "            # If dec_inp are fed into decoder as inputs, this is 'guided' training; otherwise only the\n",
    "            # first element will be fed as decoder input which is then 'un-guided'\n",
    "            dec_inp = [ tf.zeros_like(target_seq[0], dtype=tf.float32, name=\"GO\") ] + target_seq[:-1]\n",
    "\n",
    "            with tf.variable_scope('LSTMCell'):\n",
    "                cells = []\n",
    "                for i in range(self.config.num_stacked_layers):\n",
    "                    with tf.variable_scope('RNN_{}'.format(i)):\n",
    "                        cells.append(tf.contrib.rnn.LSTMCell(self.config.hidden_dim))\n",
    "                cell = tf.contrib.rnn.MultiRNNCell(cells)\n",
    "\n",
    "            def _rnn_decoder(decoder_inputs,\n",
    "                            initial_state,\n",
    "                            cell,\n",
    "                            loop_function=None,\n",
    "                            scope=None):\n",
    "\n",
    "                with variable_scope.variable_scope(scope or \"rnn_decoder\"):\n",
    "                    state = initial_state\n",
    "                    outputs = []\n",
    "                    prev = None\n",
    "                    for i, inp in enumerate(decoder_inputs):\n",
    "                        if loop_function is not None and prev is not None:\n",
    "                            with variable_scope.variable_scope(\"loop_function\", reuse=True):\n",
    "                                inp = loop_function(prev, i)\n",
    "                        if i > 0:\n",
    "                            variable_scope.get_variable_scope().reuse_variables()\n",
    "                        output, state = cell(inp, state)\n",
    "                        outputs.append(output)\n",
    "                        if loop_function is not None:\n",
    "                            prev = output\n",
    "                return outputs, state\n",
    "\n",
    "            def _basic_rnn_seq2seq(encoder_inputs,\n",
    "                                  decoder_inputs,\n",
    "                                  cell,\n",
    "                                  feed_previous,\n",
    "                                  dtype=dtypes.float32,\n",
    "                                  scope=None):\n",
    "\n",
    "                with variable_scope.variable_scope(scope or \"basic_rnn_seq2seq\"):\n",
    "                    enc_cell = copy.deepcopy(cell)\n",
    "                    _, enc_state = rnn.static_rnn(enc_cell, encoder_inputs, dtype=dtype)\n",
    "                    if feed_previous:\n",
    "                        return _rnn_decoder(decoder_inputs, enc_state, cell, _loop_function)\n",
    "                    else:\n",
    "                        return _rnn_decoder(decoder_inputs, enc_state, cell)\n",
    "\n",
    "            def _loop_function(prev, _):\n",
    "\n",
    "                return tf.matmul(prev, weights['out']) + biases['out']\n",
    "\n",
    "            dec_outputs, dec_memory = _basic_rnn_seq2seq(\n",
    "                enc_inp,\n",
    "                dec_inp,\n",
    "                cell,\n",
    "                feed_previous = feed_previous\n",
    "            )\n",
    "\n",
    "            reshaped_outputs = [tf.matmul(i, weights['out']) + biases['out'] for i in dec_outputs]\n",
    "\n",
    "        # Training loss and optimizer\n",
    "        with tf.variable_scope('Loss'):\n",
    "            # L2 loss\n",
    "            output_loss = 0\n",
    "            for _y, _Y in zip(reshaped_outputs, target_seq):\n",
    "                output_loss += tf.reduce_mean(tf.pow(_y - _Y, 2)) #MSE\n",
    "\n",
    "            # L2 regularization for weights and biases\n",
    "            reg_loss = 0\n",
    "            for tf_var in tf.trainable_variables():\n",
    "                if 'Biases_' in tf_var.name or 'Weights_' in tf_var.name:\n",
    "                    reg_loss += tf.reduce_mean(tf.nn.l2_loss(tf_var)) \n",
    "\n",
    "            loss = output_loss + self.config.lambda_l2_reg * reg_loss \n",
    "\n",
    "        with tf.variable_scope('Optimizer'):\n",
    "            optimizer = tf.contrib.layers.optimize_loss(\n",
    "                    loss=loss,\n",
    "                    learning_rate=self.config.learning_rate,\n",
    "                    global_step=global_step,\n",
    "                    optimizer='Adam',\n",
    "                    clip_gradients=self.config.GRADIENT_CLIPPING)\n",
    "\n",
    "        saver = tf.train.Saver\n",
    "\n",
    "        return dict(\n",
    "            enc_inp = enc_inp,\n",
    "            target_seq = target_seq,\n",
    "            train_op = optimizer,\n",
    "            loss=loss,\n",
    "            saver = saver,\n",
    "            reshaped_outputs = reshaped_outputs,\n",
    "            )\n",
    "    \n",
    "\n",
    "    \n",
    "    def rescale_data(self,data,scaling_factor,scaling_bias):\n",
    "        return data*scaling_factor + scaling_bias\n",
    "\n",
    "    \n",
    "    \n",
    "    def mse(self,data,new_data):\n",
    "        return np.mean((data-new_data)**2)\n",
    "\n",
    "\n",
    "    \n",
    "    def mape(self,data,new_data):\n",
    "        return np.mean(np.abs((data - new_data) / data)) * 100\n",
    "    \n",
    "    \n",
    "    \n",
    "    def train(self,X,Y):\n",
    "        \n",
    "\n",
    "        train_losses = []\n",
    "#         val_losses = []\n",
    "\n",
    "        rnn_model = self.build_graph(feed_previous=False)\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "        print(\"Saver init\")\n",
    "        init = tf.global_variables_initializer()\n",
    "        print(\"Started and initialised\")\n",
    "\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init)\n",
    "\n",
    "\n",
    "            for e in range(self.config.epochs):\n",
    "                print(e+1,'/',self.config.epochs)\n",
    "                for i in range(0,X.shape[0],self.config.batch_size):\n",
    "                    \n",
    "                    # Try to get batch size, otherwise use remaining data\n",
    "                    try:\n",
    "                    \n",
    "                        batch_X_train = np.reshape(X[i:i+self.config.batch_size],(self.config.batch_size,len(X[0]),1))\n",
    "                        batch_Y_train = np.reshape(Y[i:i+self.config.batch_size],(self.config.batch_size,len(Y[0])))\n",
    "                        \n",
    "                    except:\n",
    "                        batch_X_train = np.reshape(X[i:],(X[i:].shape[0],len(X[0]),1))\n",
    "                        batch_Y_train = np.reshape(Y[i:],(Y[i:].shape[0],len(Y[0])))\n",
    "\n",
    "                    feed_dict = {rnn_model['enc_inp'][t]: batch_X_train[:,t].reshape(-1,self.config.input_dim) for t in range(self.config.input_seq_len)} #input\n",
    "                    feed_dict.update({rnn_model['target_seq'][t]: batch_Y_train[:,t].reshape(-1,self.config.output_dim) for t in range(self.config.output_seq_len)}) #target output\n",
    "                    _, loss_t = sess.run([rnn_model['train_op'], rnn_model['loss']], feed_dict)\n",
    "#                     print(loss_t)\n",
    "                    train_losses = np.append(train_losses,loss_t)\n",
    "\n",
    "        # #             batch_val_input,batch_val_output = get_val_data()\n",
    "        # #             # Validation set \n",
    "        # #             feed_dict = {rnn_model['enc_inp'][t]: batch_val_input[t].reshape(1,1) for t in range(input_seq_len)}\n",
    "        # #             feed_dict.update({rnn_model['target_seq'][t]: np.zeros([1, output_dim]) for t in range(output_seq_len)})\n",
    "        # #             final_preds = sess.run(rnn_model['reshaped_outputs'], feed_dict)\n",
    "\n",
    "        # #             val_losses = np.append(val_losses,mse(final_preds,batch_val_output[0]))\n",
    "\n",
    "\n",
    "            temp_saver = rnn_model['saver']()\n",
    "            save_path = temp_saver.save(sess, os.path.join(self.config.save_path, self.config.save_name))\n",
    "            \n",
    "            plt.plot(train_losses)\n",
    "#             print(\"Model saved at: \", self.config,save_path,self.config.save_name)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def backtest(self,X,Y,wallet):\n",
    "        print(\"Backtesting...\")\n",
    "\n",
    "        self.wallet = wallet\n",
    "        start = True\n",
    "        \n",
    "        policy = policy_generator(wallet)\n",
    "        self.wallet_change = [wallet]\n",
    "        predictions = np.array([])\n",
    "        \n",
    "\n",
    "        rnn_model = self.build_graph(feed_previous=True) \n",
    "        init = tf.global_variables_initializer()\n",
    "        with tf.Session() as sess:\n",
    "\n",
    "            sess.run(init)\n",
    "            saver = rnn_model['saver']().restore(sess, os.path.join(self.config.save_path, self.config.save_name))\n",
    "\n",
    "        \n",
    "            for i in range(X.shape[0]):\n",
    "                backtest_X = np.reshape(X[i],(len(X[i]),1))\n",
    "                backtest_Y = np.reshape(Y[i],(len(Y[i],)))\n",
    "                \n",
    "\n",
    "                feed_dict = {rnn_model['enc_inp'][t]: backtest_X[t].reshape(-1,self.config.input_dim) for t in range(self.config.input_seq_len)}\n",
    "                feed_dict.update({rnn_model['target_seq'][t]: np.zeros([1, self.config.output_dim]) for t in range(self.config.output_seq_len)})\n",
    "                forecast = np.asarray(sess.run(rnn_model['reshaped_outputs'], feed_dict))\n",
    "\n",
    "\n",
    "                \n",
    "                updated_policy = policy.update(forecast,start)\n",
    "                policy.execute_policy(updated_policy,true_data = self.rescale_data(backtest_Y,self.config.scaling_factor,self.config.scaling_bias))\n",
    "                start = False\n",
    "                \n",
    "                print(updated_policy)\n",
    "#                 policy.generate(self.rescale_data(forecast,self.config.scaling_factor,self.config.scaling_bias))\n",
    "\n",
    "#                 policy.execute_policy(true_data = self.rescale_data(backtest_Y,self.config.scaling_factor,self.config.scaling_bias))\n",
    "                self.wallet_change = np.append(self.wallet_change,policy.wallet)\n",
    "       \n",
    "        self.wallet = policy.wallet\n",
    "        # Sell all at the end here!!!\n",
    "        print(\"Complete\")\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class configuration():\n",
    "    \n",
    "    def __init__(self,scaling_factor,scaling_bias,forecast_horizon,input_seq_len):\n",
    "        \n",
    "        # Data scaling factor and bias\n",
    "        self.scaling_factor = scaling_factor\n",
    "        self.scaling_bias = scaling_bias\n",
    "        # Input seq length\n",
    "        self.input_seq_len = input_seq_len\n",
    "        # Output sequence length\n",
    "        self.output_seq_len = forecast_horizon\n",
    "        # Num of hidden cells\n",
    "        self.hidden_dim = 128\n",
    "        # Num of input signals\n",
    "        self.input_dim = 1\n",
    "        # Num of output signals\n",
    "        self.output_dim = 1\n",
    "        # Num of stacked lstm layers\n",
    "        self.num_stacked_layers = 1\n",
    "        # Gradient clipping - to avoid gradient exploding\n",
    "        self.GRADIENT_CLIPPING = 2.5\n",
    "        # Num of training epochs\n",
    "        self.epochs = 1\n",
    "        # Save path\n",
    "        self.save_path = 'models/minute/1_layer/'\n",
    "        # Save name\n",
    "        self.save_name = '25epoch_shuffled'\n",
    "        # Learning rate\n",
    "        self.learning_rate = 0.001\n",
    "        # L2 regularisation constant\n",
    "        self.lambda_l2_reg = 0.001\n",
    "        self.batch_size = 128\n",
    "\n",
    "\n",
    "# Network parameter configuration\n",
    "config = configuration(scaling_factor,scaling_bias,forecast_horizon,input_seq_len)\n",
    "\n",
    "# # # Initial wallet amount\n",
    "wallet = 1000\n",
    "\n",
    "# # # Set network parameters\n",
    "mod = model(config)\n",
    "\n",
    "# # # Train network\n",
    "mod.train(X_train,Y_train)\n",
    "\n",
    "# Backtest\n",
    "mod.backtest(X_val,Y_val,wallet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
